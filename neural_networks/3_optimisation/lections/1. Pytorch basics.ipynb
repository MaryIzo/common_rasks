{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/pytorch_basics/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# ================================================================== #\n",
    "#                         Table of Contents                          #\n",
    "# ================================================================== #\n",
    "\n",
    "# 1. Basic autograd example 1               (Line 25 to 39)\n",
    "# 2. Basic autograd example 2               (Line 46 to 83)\n",
    "# 3. Loading data from numpy                (Line 90 to 97)\n",
    "# 4. Input pipline                          (Line 104 to 129)\n",
    "# 5. Input pipline for custom dataset       (Line 136 to 156)\n",
    "# 6. Pretrained model                       (Line 163 to 176)\n",
    "# 7. Save and load model                    (Line 183 to 189) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================== #\n",
    "#                     1. Basic autograd example 1                    #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[ 0.3279, -0.4911, -0.4888],\n",
      "        [-0.1475,  0.4737, -0.1042]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.2334, -0.3609], requires_grad=True)\n",
      "0 loss:  1.242653489112854\n",
      "1 loss:  1.2276136875152588\n",
      "2 loss:  1.21290123462677\n",
      "3 loss:  1.1985089778900146\n",
      "4 loss:  1.1844292879104614\n",
      "5 loss:  1.170655369758606\n",
      "6 loss:  1.1571801900863647\n",
      "7 loss:  1.1439969539642334\n",
      "8 loss:  1.131098985671997\n",
      "9 loss:  1.1184799671173096\n",
      "10 loss:  1.1061334609985352\n",
      "11 loss:  1.0940535068511963\n",
      "12 loss:  1.0822337865829468\n",
      "13 loss:  1.0706686973571777\n",
      "14 loss:  1.0593522787094116\n",
      "15 loss:  1.048279047012329\n",
      "16 loss:  1.0374435186386108\n",
      "17 loss:  1.0268402099609375\n",
      "18 loss:  1.016464114189148\n",
      "19 loss:  1.0063098669052124\n",
      "20 loss:  0.9963725805282593\n",
      "21 loss:  0.9866472482681274\n",
      "22 loss:  0.9771292805671692\n",
      "23 loss:  0.9678139686584473\n",
      "24 loss:  0.958696722984314\n",
      "25 loss:  0.9497731328010559\n",
      "26 loss:  0.9410387873649597\n",
      "27 loss:  0.9324894547462463\n",
      "28 loss:  0.9241209626197815\n",
      "29 loss:  0.91592937707901\n",
      "30 loss:  0.9079105257987976\n",
      "31 loss:  0.900060772895813\n",
      "32 loss:  0.8923762440681458\n",
      "33 loss:  0.8848531246185303\n",
      "34 loss:  0.8774878978729248\n",
      "35 loss:  0.8702770471572876\n",
      "36 loss:  0.8632171154022217\n",
      "37 loss:  0.8563047647476196\n",
      "38 loss:  0.849536657333374\n",
      "39 loss:  0.842909574508667\n",
      "40 loss:  0.8364203572273254\n",
      "41 loss:  0.8300659656524658\n",
      "42 loss:  0.8238433599472046\n",
      "43 loss:  0.8177496194839478\n",
      "44 loss:  0.8117819428443909\n",
      "45 loss:  0.8059375286102295\n",
      "46 loss:  0.8002135157585144\n",
      "47 loss:  0.7946072816848755\n",
      "48 loss:  0.7891162633895874\n",
      "49 loss:  0.7837379574775696\n",
      "50 loss:  0.7784696817398071\n",
      "51 loss:  0.7733091115951538\n",
      "52 loss:  0.7682539224624634\n",
      "53 loss:  0.7633016705513\n",
      "54 loss:  0.7584501504898071\n",
      "55 loss:  0.7536971569061279\n",
      "56 loss:  0.749040424823761\n",
      "57 loss:  0.7444779276847839\n",
      "58 loss:  0.7400074601173401\n",
      "59 loss:  0.7356271147727966\n",
      "60 loss:  0.7313348650932312\n",
      "61 loss:  0.727128803730011\n",
      "62 loss:  0.7230069637298584\n",
      "63 loss:  0.718967616558075\n",
      "64 loss:  0.7150087952613831\n",
      "65 loss:  0.7111288905143738\n",
      "66 loss:  0.7073260545730591\n",
      "67 loss:  0.70359867811203\n",
      "68 loss:  0.6999450325965881\n",
      "69 loss:  0.6963635683059692\n",
      "70 loss:  0.6928526759147644\n",
      "71 loss:  0.6894108057022095\n",
      "72 loss:  0.6860365271568298\n",
      "73 loss:  0.6827282905578613\n",
      "74 loss:  0.6794846653938293\n",
      "75 loss:  0.676304280757904\n",
      "76 loss:  0.6731857061386108\n",
      "77 loss:  0.6701276898384094\n",
      "78 loss:  0.66712886095047\n",
      "79 loss:  0.6641879081726074\n",
      "80 loss:  0.6613036394119263\n",
      "81 loss:  0.6584747433662415\n",
      "82 loss:  0.6557000875473022\n",
      "83 loss:  0.6529785394668579\n",
      "84 loss:  0.6503088474273682\n",
      "85 loss:  0.6476899981498718\n",
      "86 loss:  0.6451207995414734\n",
      "87 loss:  0.6426001787185669\n",
      "88 loss:  0.6401272416114807\n",
      "89 loss:  0.6377007961273193\n",
      "90 loss:  0.6353198885917664\n",
      "91 loss:  0.6329836249351501\n",
      "92 loss:  0.6306909918785095\n",
      "93 loss:  0.6284410357475281\n",
      "94 loss:  0.6262328624725342\n",
      "95 loss:  0.6240655183792114\n",
      "96 loss:  0.6219382882118225\n",
      "97 loss:  0.6198501586914062\n",
      "98 loss:  0.6178004145622253\n",
      "99 loss:  0.6157881021499634\n",
      "loss after 1 step optimization:  0.6138125658035278\n"
     ]
    }
   ],
   "source": [
    "# ================================================================== #\n",
    "#                    2. Basic autograd example 2                     #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create tensors of shape (10, 3) and (10, 2).\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "# Build loss function and optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(100):\n",
    "    # Forward pass.\n",
    "    pred = linear(x)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = criterion(pred, y)\n",
    "    print(i, 'loss: ', loss.item())\n",
    "\n",
    "    # Backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Print out the gradients.\n",
    "    #print ('dL/dw: ', linear.weight.grad) \n",
    "    #print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "    # 1-step gradient descent.\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# You can also perform gradient descent at the low level.\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# Print out the loss after 1-step gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                     3. Loading data from numpy                     #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create a numpy array.\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "#y = torch.tensor(x)\n",
    "\n",
    "# Convert the torch tensor to a numpy array.\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.3 µs ± 969 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(100000)\n",
    "y = np.random.randn(100000)\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5 µs ± 1.46 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.random.randn(100000)).to('cpu')\n",
    "y = torch.tensor(np.random.randn(100000)).to('cpu')\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 µs ± 7.36 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.random.randn(100000)).to('cuda')\n",
    "y = torch.tensor(np.random.randn(100000)).cuda()\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# ================================================================== #\n",
    "#                         4. Input pipeline                           #\n",
    "# ================================================================== #\n",
    "\n",
    "# Download and construct CIFAR-10 dataset.\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "\n",
    "# Fetch one data pair (read data from disk).\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)\n",
    "\n",
    "# Data loader (this provides queues and threads in a very simple way).\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of the data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Training code should be written here.\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 5)\n",
    "y = torch.randn(100, 1)\n",
    "dataset = torch.utils.data.TensorDataset(x, y)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=10, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005],\n",
      "        [-1.0344,  1.0966,  0.0292,  0.2165,  0.6746],\n",
      "        [ 0.6224,  0.7937, -0.9416,  0.1784, -0.4309],\n",
      "        [ 1.0065,  0.1071, -0.3768,  0.7618, -0.0308],\n",
      "        [-0.3101, -0.5885,  1.0506, -1.2406,  0.8871],\n",
      "        [-0.9963,  1.0351,  2.1234,  0.5735, -0.0910],\n",
      "        [ 1.1783,  0.1793,  0.1165,  0.7647, -0.0882],\n",
      "        [-0.5113,  0.3593, -0.4507,  0.7896, -1.9649],\n",
      "        [-0.1998, -0.3947, -0.3703, -2.2381,  0.2017],\n",
      "        [-2.3404, -0.3899,  0.1733,  2.2053, -0.6725]])\n",
      "tensor([[-1.1190],\n",
      "        [ 0.7378],\n",
      "        [ 0.0999],\n",
      "        [-1.1138],\n",
      "        [-0.1022],\n",
      "        [-0.8227],\n",
      "        [-0.7476],\n",
      "        [ 1.4706],\n",
      "        [-0.0587],\n",
      "        [ 1.4130]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in loader:\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005]), tensor([-1.1190])),\n",
       " tensor([ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005]),\n",
       " tensor([-1.1190]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                5. Input pipeline for custom dataset                 #\n",
    "# ================================================================== #\n",
    "import os\n",
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_name):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        self.folder_name = folder_name\n",
    "        self.files = os.listdir(self.folder_name)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return self.files[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.files)\n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset(folder_name='.')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.ipynb_checkpoints'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4. Feed forward neural network.ipynb', 'model.ckpt', 'pytorch-tutorial-master.zip', 'science.pdf']\n"
     ]
    }
   ],
   "source": [
    "for names in train_loader:\n",
    "    print(names)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "len(a), a.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)\n",
    "a[1], a.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                        6. Pretrained model                         #\n",
    "# ================================================================== #\n",
    "\n",
    "# Download and load the pretrained ResNet-18.\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only the top layer of the model, set as below.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
    "\n",
    "# Forward pass.\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                      7. Save and load the model                    #\n",
    "# ================================================================== #\n",
    "\n",
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')\n",
    "\n",
    "# Save and load only the model parameters (recommended).\n",
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
